# 📚 Book_wave

### 🔖 서비스 개요

- **서비스 기획 배경**: 
	중고책 거래는 지속 가능한 소비를 촉진하고 환경 보호에 기여합니다. 
	이는 책을 재사용하여 자원 소모를 줄이고, 더 많은 사람들이 저렴하게 지식을 접할 수 있도록 돕습니다. 
	따라서 중고책을 위한 신뢰할 수 있는 플랫폼을 구축하여 사용자들에게 더 나은 경험을 제공하는 것이 필요합니다.
- **서비스 기대 효과**:
	중고책 거래는 친환경 소비 문화를 확산시키고, 독서와 학습의 기회를 확대합니다. 
	환경 보호와 지식 공유를 결합한 지속 가능한 모델로 사회에 긍정적인 영향을 미칩니다.
  
### 🔗 주요 기능

#### 1️⃣ 간편 회원가입 및 로그인
- 카카오 소셜 로그인 연동으로 회원가입 및 로그인 절차 간소화
- OAuth 2.0 기반 인증 및 보안 강화

#### 2️⃣ 정렬 및 무한 스크롤 리스트
- 다양한 정렬(최신순, 인기순, 가격순 등) 기능 제공
- 무한 스크롤 리스트로 사용자 경험 향상

#### 3️⃣ 즐겨찾기 및 찜 기능
- 주요 검색어 즐겨찾기 등록으로 빠른 매물 탐색 지원
- 찜 기능을 통해 관심 매물의 상태 추적 가능

#### 4️⃣ 알림 시스템
- 즐겨찾기 및 찜 목록에 대한 실시간 알림 제공
- 거래 상태, 가격 변동 등 주요 이벤트 알림

#### 5️⃣ 데시벨 등급 사용자 분류
- 거래 활동을 기반으로 사용자를 데시벨 단위로 분류
- 책을 메인 콘텐츠로 하여, 똑똑한 동물(돌고래) 컨셉의 등급 시스템 적용

#### 6️⃣ 사용자 간 채팅 및 거래 관리
- 판매자와 구매자 간 1:1 채팅 기능 제공
- 거래 상태(진행, 완료 등) 저장 및 관리

#### 7️⃣ 정가 및 가격 비교
- 도서 API 연동을 통한 실시간 정가 및 시세 정보 제공
- 다양한 매물 간 가격 비교 기능 지원

---

**서비스 아키텍처**

<img width="783" alt="Image" src="https://github.com/user-attachments/assets/072f3678-6795-4746-8d7c-04832043f8b6" />

### 🌈 개선 사항

#### 1️⃣ 닉네임 조회 방식 개선 - <ins>token claim 활용 성능 개선</ins>

**📌 문제 상황**  
- 1대1 채팅 진입 시, 사용자의 member id를 가지고 다시 닉네임을 조회해야하는 불필요한 DB 접근이 필요.
- 매번 인증 단계에서 추가적인 DB 접근으로 병목 현상이 발생.

**✅ 개선 방향**  
- **token claim에 사용자 닉네임** 추가 : 사용자의 닉네임을 access token의 claim에 포함시켜, DB에 대한 불필요한 조회를 최소화.
- **token 헤더의 크기 증가** 에 대한 해결 : 토큰 헤더의 크기는 약 31바이트 증가(920바이트 → 951바이트)했지만, 이는 DB 접근을 줄이는 것에 비해 미미한 오버헤드.
<img width="533" alt="Image" src="https://github.com/user-attachments/assets/ff22f69a-e332-4aa8-b019-ddc044afb20d" />

---

#### 2️⃣ 채팅 기능 고도화 ( 메세지 큐 적용 ) - <ins>TPS 약 ??% 상승</ins>

**📌 문제 상황**  
- 단일 서버에서 약 100명의 유저가 동시에 1000개의 메세지를 같은 채팅방에 보낼 경우,  트래픽 누적으로 인한 **HTTP 504 Gateway Timeout** 발생  
- TPS 또한 ??으로 매우 낮음

**✅ 개선 방향**  
- Netty-Websocket 및 RabbitMQ를 통해 성능 및 기능 비교 후 성능 고도화

**1️⃣** Netty-Websocket
- Netty 프레임워크 기반으로 websocket 통신 최적화 하여 ~~
- 네티에 대한 추가설명

**📈 **
<img width="517" alt="인메모리 캐싱 적용" src="https://github.com/user-attachments/assets/4032895f-9b6f-42f0-a494-44b737582506" />

**2️⃣** 메세지 큐
- 프로젝트 기간을 반영한 학습 곡선 및 메세지 복구 전략에 대한 DeadLetter Queue 구현이 용이한 RabbitMQ 선택
- 이후 확장에서도 용이하다 ~~

**📈 **
<img width="517" alt="인메모리 캐싱 적용" src="https://github.com/user-attachments/assets/4032895f-9b6f-42f0-a494-44b737582506" />

** 성능 비교 **

| 기준                | Netty-WebSocket                          | RabbitMQ                              |
|---------------------|------------------------------------------|---------------------------------------|
| **최대 TPS**        | 70K/s (단일 서버)                       | 50K/s (단일 노드), 클러스터링 시 확장 |
| **지연 시간**       | 1ms~3ms                                 | 2ms~15ms                             |
| **장애 복구**       | 수동 구현 필요                          | DLQ/미러링큐 자동 복구         |
| **개발 복잡도**     | 프로토콜 핸들러 직접 구현                | 스프링 통합으로 신속 적용      |
| **확장성**          | 로드밸런서 추가 필요                    | 클러스터 자동 확장            |
| **최적 사용 사례**  | 초저지연 1:1 통신                       | 복잡한 메시지 라우팅/재시도 필요 시  |


**📉 개선 전**
<img width="515" alt="DB findAll 기반 종가 조회" src="https://github.com/user-attachments/assets/68d4f328-eaaf-4c13-9689-9896ef3ca129" />

**📈 개선 후**
<img width="517" alt="인메모리 캐싱 적용" src="https://github.com/user-attachments/assets/4032895f-9b6f-42f0-a494-44b737582506" />

**결론**
- 

---

#### 3️⃣ 서버 간 통신 속도 개선 - <ins>gRPC 적용</ins>

**📌 문제 상황**  
- 기존 RESTTemplate (HTTP/1.1) 기반의 동기 통신 구조  
  - TCP 3-way handshake  
  - JSON 직렬화 / 역직렬화 비용  
  - 과도한 헤더 크기로 인한 지연

**✅ 개선 방향**  
- **gRPC (HTTP/2 기반)** 적용  
  - 직렬화 비용 절감 (바이너리 기반)  
  - TCP 연결 재사용으로 성능 향상  

**⏱ 성능 비교**

- **RestTemplate (HTTP / 1.1)**  
  <img width="615" alt="RestTemplate(http / 1.1)" src="https://github.com/user-attachments/assets/90154579-82a6-4247-9be5-b316aed5a548" />

- **RestTemplate (HTTP / 2)**  
  <img width="625" alt="RestTemplate(http / 2)" src="https://github.com/user-attachments/assets/4fff0191-325f-4871-bf5c-4c3d19222c42" />

- **gRPC**  
  <img width="669" alt="gRPC" src="https://github.com/user-attachments/assets/7e24f753-398a-455a-98d4-34adda48ffea" />

